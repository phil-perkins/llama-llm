{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c12a9e9-4864-4d3b-a381-8e6bbf549b0d",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "### Install PyTorch\n",
    "\n",
    "As I have an NVIDIA GPU, I can use PyTorch with CUDA for GPU acceleration.\n",
    "[PyTorch Guide](https://pytorch.org/get-started/locally/)\n",
    "\n",
    "To check your NVIDIA CUDA version:\n",
    "1. Open NVIDIA Control Panel\n",
    "2. Expand Help, and click System Information\n",
    "3. Go to the Components Tab\n",
    "4. Look for CUDA under 3D Settings, for example 'NVCUDA64.DLL', and check the version in the Product Name, for example 'NVIDIA CUDA __12.8.51__ driver'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d7ee14-a8a4-466d-b6c2-dd56fc8489db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The below needs to be run on your system terminal.\n",
    "\n",
    "#pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54c0e47-a277-411f-8e15-161e1a8ffdae",
   "metadata": {},
   "source": [
    "### Verify PyTorch Installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9741b7f0-cfb4-4d5a-9377-febdb52c9346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()\n",
    "\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0b8aa5-6027-4e6a-9755-e5145e97b793",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "\n",
    "_torch commented out as it is imported above_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ba6a17-3e25-4a1a-ae74-ff994e891e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "import transformers\n",
    "import os\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab607532-4bf8-4ef1-81fc-1450d4218818",
   "metadata": {},
   "source": [
    "### Authenticate Hugging Face\n",
    "\n",
    "If you do not authenticate you will get a 401 error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d3f4d7-f1b8-4058-a10f-30a92db84b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import VBox\n",
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e7aff3-82bb-4d06-9a14-ddf4e85e297b",
   "metadata": {},
   "source": [
    "### Choose the model\n",
    "\n",
    "Download the model from [Hugging Face](https://huggingface.co/meta-llama), or use transformers to handle it. The following code block is taken from the [Llama 3.3 70B Instruct](https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct) model example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb339ea-4344-4dd1-98d4-1a9db1e7db1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    #system: defines how the LLM behaves\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    #user: defines the input provided by the user\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6a040a-bb06-43e4-8111-b935bf234f81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
